mu.ref<-mean(ddiff, na.rm=T)
sd.ref<-sd(ddiff, na.rm=T)
#Compute excursions in test period and get z-score
tmin<-min(testy$tt) # minimum time in test period
tmax<-max(testy$tt) # maximum time in test period
wind<-seq(from=tmin, to=tmax, by=stride*dtt)
ddiff<-rep(NA, length(wind))
zz<-rep(NA, length(wind))
for(ww in 1:length(wind)){
ltest<-wind[ww]-wwidth*dtt/2 #left side of test window
if(ltest < tmin){next} #skip indices where window overhangs beginning of time series
rtest<-wind[ww]+wwidth*dtt/2 #right side of test window
if(rtest > tmax){break} #stop computation when window overhands end of time series
if(rtest > ltest){
tpd<-testy$tt > ltest & testy$tt <= rtest
}
if(rtest < ltest){
tpd<-testy$tt > ltest | testy$tt <= rtest
}
lref<-(testy$doy[abs(testy$tt-wind[ww]) < dtt/10]-refwidth*dt/2) %% 365 #left side of reference window
if(length(lref)==0){next}#enables skipping indices when time series are gappy
if(lref==0){lref==365}
rref<-(testy$doy[abs(testy$tt-wind[ww]) < dtt/10]+refwidth*dt/2) %% 365 #right side of reference window
if(rref==0){rref==365}
if(rref > lref){
rpd<-refy$doy > lref & refy$doy <= rref
}
if(rref < lref){
rpd<-refy$doy > lref | refy$doy <= rref
}
#check if sufficient non-missing values in reference and test periods
if(sum(!is.na(testy$yy[tpd]))/wwidth < dmin | sum(!is.na(refy$yy[rpd]))/refwidth < dmin){
next
}
refdist<-ecdf(refy$yy[rpd])
wdist<-ecdf(testy$yy[tpd])
if(ddiff_method == "dist"){
ddiff[ww]<-max(abs(refdist(xx)-wdist(xx)))
}else if(ddiff_method == "integral"){
ddiff[ww]<-dx*sum(abs(refdist(xx)-wdist(xx)))
}
zz[ww]<-(ddiff[ww]-mu.ref)/sd.ref
}
wleft<-wind-wwidth*dtt/2
wright<-wind+wwidth*dtt/2
} #close if statement for date-formatted data
} #close if statement for adaptive reference window
return(data.frame(wleft=wleft,wright=wright,ddiff=ddiff,zz=zz))
}
testint <-mwdistdiffz(testy_R15,refy,
wwidth=10, stride=1, refwidth = 120,
ddiff_method = "integral")
testint
#This program calculates epilimnetic chlorphyll using Cascade data for selected years
#Method requires aligning the data with the proper light depths listed in order
#throughout the data set.
# library(devtools)
# install_github("jonathan-walter/disturbhf")
library(disturbhf)
rm(list = ls())
graphics.off()
# Sets directory
# setwd("~/Cascade/Disturbance HF Analysis")
#Read in Data
data1 <- read.csv("Cascade_Chlorophyll_Data_All.csv", header=T, stringsAsFactors = FALSE)
#Get data for Peter Lake
data2 <- data1[data1$lakeid=="R",]
#pull out certain years
yearsWant = c(2001, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012,2016)
data3 = data2[data2$year4 %in% yearsWant,]
#Further trim data to pull out identifying columns and chlorophyll
data4 = data3[,c("lakeid","year4","daynum","sampledate","depth","depth_id","chla")]
#Eliminate light depths greater than 3 to estimate epilimnetic #chlorophyll
data5=subset(data4,depth_id %in% 1:3)
#New column with chlorophyll data as numeric values (not characters)
data5$chla_2 = as.numeric(data5$chla)
#Find the number of unique values in each column of data5 and assign to vector
unique.values <-sapply(data5,function(x)length(unique(x)))
#The number of unique dates, to use as a counter
n1 = unique.values[4]
#The length of data2 to use as a counter
n2 = length(data5$lakeid)
#Set Up x and y vectors for means
x = data5[,5]
y = data5[,8]
#Set up counter, k, and vector to hold data
k = 1
chl_epi = c(1:n1)
#Loop for calculating eplimnetic mean from depth 100% to 25% light
#Note light depth data must be perfectly aligned throughout the data set for
#this approach to work.
for (i in 1:n1){
j=k+2
x1 = x[k:j]
y1 = y[k:j]
chl_epi [i] <- mean(y1, na.rm=TRUE)
k=k+3
}
#Join calculated eplimnetic  chlorophyll values with appropriate year, day
#and create a new dateset with thes values plus numeric date markers
data6 = data.frame(date=unique(data5$sampledate),chl_epi=chl_epi)
data6$date2 = as.Date(data6$date,format="%m/%d/%Y") #sets date format
data6$year = as.numeric(format(data6$date2,format="%Y")) #creates a year column
data6$DOY = as.integer(format(data6$date2,format="%j")) #creates a day of year column
#Daily Cascade Data for Years 2011 to 2019; Data curated by Cal Buelo
#and posted on NTL LTER
#Disturbance program from Cal Buelo modified by Dat Ha
library(tidyverse)
library(disturbhf)
dat <- read.csv("allyears.csv")
#Create experimental and reference data sets
#Filtered out early days of the time series because these are sometimes at high values relative to the rest of the year.
#Start with day 140
dat15 <- dat %>% filter(Year == 2015) %>% filter(Lake=='R') %>%
filter(DOYtrunc>139)
dat11 <- dat %>% filter(Year == 2011) %>% filter(Lake=='R')%>%
filter(DOYtrunc>139)
#2016 doesn't have manual Chl but has everything else
dat16 <- dat %>% filter(Year == 2016) %>% filter(Lake=='R') %>% filter(DOYtrunc>139)
dat18 <- dat %>% filter(Year == 2018) %>% filter(Lake=='R') %>% filter(DOYtrunc>139)
join1 <- rbind(dat11,dat16)
refyears <- rbind(join1, dat18)
# refyears <- data6
#test 3 - chl
refy = data.frame(tt=unname(refyears$DOYtrunc), yy=unname(refyears$Manual_Chl))
# refy = data.frame(tt=unname(refyears$DOY),
#                  yy=unname(refyears$chl_epi))
testy_R15 = data.frame(tt=unname(dat15$DOYtrunc), yy=unname(dat15$Manual_Chl))
# windows()
plot(testy_R15, col="blue")
points(refy, col="black")
testint <-mwdistdiffz(testy_R15,refy,
wwidth=10, stride=1, refwidth = 120,
ddiff_method = "integral")
refyears <- rbind(join1, dat18)
refyears
head(refyears)
refyears <- data6
refyears
refy = data.frame(tt=unname(refyears$DOYtrunc), yy=unname(refyears$Manual_Chl))
refy = data.frame(tt=unname(refyears$DOY),
yy=unname(refyears$chl_epi))
refy
plot(refy)
setwd("~/Documents/Research/disturbhf_project")
rm(list = ls())
graphics.off()
data1 <- read.csv("Cascade_Chlorophyll_Data_All.csv", header=T, stringsAsFactors = FALSE)
#Get data for Peter Lake
data2 <- data1[data1$lakeid=="R",]
#pull out certain years
yearsWant = c(2001, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012,2016)
data3 = data2[data2$year4 %in% yearsWant,]
#Further trim data to pull out identifying columns and chlorophyll
data4 = data3[,c("lakeid","year4","daynum","sampledate","depth","depth_id","chla")]
#Eliminate light depths greater than 3 to estimate epilimnetic #chlorophyll
data5=subset(data4,depth_id %in% 1:3)
#New column with chlorophyll data as numeric values (not characters)
data5$chla_2 = as.numeric(data5$chla)
#Find the number of unique values in each column of data5 and assign to vector
unique.values <-sapply(data5,function(x)length(unique(x)))
#The number of unique dates, to use as a counter
n1 = unique.values[4]
#The length of data2 to use as a counter
n2 = length(data5$lakeid)
#Set Up x and y vectors for means
x = data5[,5]
y = data5[,8]
#Set up counter, k, and vector to hold data
k = 1
chl_epi = c(1:n1)
for (i in 1:n1){
j=k+2
x1 = x[k:j]
y1 = y[k:j]
chl_epi [i] <- mean(y1, na.rm=TRUE)
k=k+3
}
data6 = data.frame(date=unique(data5$sampledate),chl_epi=chl_epi)
data6$date2 = as.Date(data6$date,format="%m/%d/%Y") #sets date format
data6$year = as.numeric(format(data6$date2,format="%Y")) #creates a year column
data6$DOY = as.integer(format(data6$date2,format="%j")) #creates a day of year column
data6
library(tidyverse)
library(disturbhf)
dat <- read.csv("allyears.csv")
dat15 <- dat %>% filter(Year == 2015) %>% filter(Lake=='R') %>%
filter(DOYtrunc>139)
dat11 <- dat %>% filter(Year == 2011) %>% filter(Lake=='R')%>%
filter(DOYtrunc>139)
#2016 doesn't have manual Chl but has everything else
dat16 <- dat %>% filter(Year == 2016) %>% filter(Lake=='R') %>% filter(DOYtrunc>139)
dat18 <- dat %>% filter(Year == 2018) %>% filter(Lake=='R') %>% filter(DOYtrunc>139)
join1 <- rbind(dat11,dat16)
#refyears <- rbind(join1, dat18)
refyears <- data6
refyears
refy = data.frame(tt=unname(refyears$DOYtrunc), yy=unname(refyears$Manual_Chl))
refy
refy = data.frame(tt=unname(refyears$DOY),
yy=unname(refyears$chl_epi))
refy
refyears
testy_R15 = data.frame(tt=unname(dat15$DOYtrunc), yy=unname(dat15$Manual_Chl))
plot(testy_R15, col="blue")
points(refy, col="black")
testint <-mwdistdiffz(testy_R15,refy,
wwidth=10, stride=1, refwidth = 120,
ddiff_method = "integral")
mwdistdiffz
testy = testy_R15
refy = refy
wwidth = 10
refwidth = 120
dx = 0.01
stride = 1
dmin = 0.5
ddiff_method = "integral"
!is.data.frame(testy) | !"tt" %in% colnames(testy) |
!"yy" %in% colnames(testy)
!is.data.frame(refy) | !"tt" %in% colnames(refy) | !"yy" %in%
colnames(refy)
any(class(testy$tt) != class(refy$tt))
nrow(testy) < 50
nrow(refy) < 50
xx <- seq(min(c(refy$yy, testy$yy), na.rm = T) - dx, max(c(refy$yy,
testy$yy), na.rm = T) + dx, dx)
is.null(refwidth)
if (is.null(refwidth)) {
if (is.numeric(testy$tt)) {
wind0 <- seq(from = ceiling(wwidth/2) + 1, to = length(refy$tt) -
ceiling(wwidth/2), by = stride)
ddiff0 <- rep(NA, length(wind0))
dt <- diff(testy$tt)[1]
for (ww in 1:length(wind0)) {
pd <- (wind0[ww] - (wwidth/2)):(wind0[ww] + wwidth/2 -
1)
if (mean(!is.na(refy$yy[pd])) < dmin) {
ddiff0[ww] <- NA
}
else {
tmprefdist <- ecdf(refy$yy[-pd])
tmpwdist <- ecdf(refy$yy[pd])
if (ddiff_method == "dist") {
ddiff0[ww] <- max(abs(tmprefdist(xx) - tmpwdist(xx)))
}
else if (ddiff_method == "integral") {
ddiff0[ww] <- dx * sum(abs(tmprefdist(xx) -
tmpwdist(xx)))
}
}
}
mu.ref <- mean(ddiff0, na.rm = T)
sd.ref <- sd(ddiff0, na.rm = T)
refdist <- ecdf(refy$yy)
wind <- seq(from = ceiling(wwidth/2) + 1, to = length(testy$tt) -
ceiling(wwidth/2), by = stride)
ddiff <- rep(NA, length(wind))
zz <- rep(NA, length(wind))
for (ww in 1:length(wind)) {
pd <- (wind[ww] - (wwidth/2)):(wind[ww] + wwidth/2 -
1)
if (mean(!is.na(testy$yy[pd])) < dmin) {
ddiff[ww] <- NA
}
else {
wdist <- ecdf(testy$yy[pd])
if (ddiff_method == "dist") {
ddiff[ww] <- max(abs(refdist(xx) - wdist(xx)))
}
else if (ddiff_method == "integral") {
ddiff[ww] <- dx * sum(abs(refdist(xx) - wdist(xx)))
}
zz[ww] <- (ddiff[ww] - mu.ref)/sd.ref
}
}
wleft <- testy$tt[wind] - wwidth * dt/2
wright <- testy$tt[wind] + wwidth * dt/2
}
if (any(grepl("POSIX", class(refy$tt)))) {
dt <- diff(testy$tt)[1]
wind0 <- seq(from = ceiling(wwidth/2) + 1, to = length(refy$tt) -
ceiling(wwidth/2), by = stride)
ddiff0 <- rep(NA, length(wind0))
for (ww in 1:length(wind0)) {
pd <- (wind0[ww] - (wwidth/2)):(wind0[ww] + wwidth/2 -
1)
if (mean(!is.na(refy$yy[pd])) < dmin) {
ddiff0[ww] <- NA
}
else {
tmprefdist <- ecdf(refy$yy[-pd])
tmpwdist <- ecdf(refy$yy[pd])
if (ddiff_method == "dist") {
ddiff0[ww] <- max(abs(tmprefdist(xx) - tmpwdist(xx)))
}
else if (ddiff_method == "integral") {
ddiff0[ww] <- dx * sum(abs(tmprefdist(xx) -
tmpwdist(xx)))
}
}
}
mu.ref <- mean(ddiff0, na.rm = T)
sd.ref <- sd(ddiff0, na.rm = T)
refdist <- ecdf(refy$yy)
wind <- seq(from = ceiling(wwidth/2) + 1, to = length(testy$tt) -
ceiling(wwidth/2), by = stride)
ddiff <- rep(NA, length(wind))
zz <- rep(NA, length(wind))
for (ww in 1:length(wind)) {
pd <- (wind[ww] - (wwidth/2)):(wind[ww] + wwidth/2 -
1)
if (mean(!is.na(testy$yy[pd])) < dmin) {
ddiff[ww] <- NA
}
else {
wdist <- ecdf(testy$yy[pd])
if (ddiff_method == "dist") {
ddiff[ww] <- max(abs(refdist(xx) - wdist(xx)))
}
else if (ddiff_method == "integral") {
ddiff[ww] <- dx * sum(abs(refdist(xx) - wdist(xx)))
}
zz[ww] <- (ddiff[ww] - mu.ref)/sd.ref
}
}
wleft <- testy$tt[wind] - wwidth * dt/2
wright <- testy$tt[wind] + wwidth * dt/2
}
}
!is.null(refwidth)
is.numeric(testy$tt)
testy$doy <- testy$tt%%365
testy$doy[testy$doy == 0] <- 365
refy$doy <- refy$tt%%365
refy$doy[refy$doy == 0] <- 365
dt <- diff(testy$doy)[1]
tmin <- min(refy$tt)
tmax <- max(refy$tt)
wind <- seq(from = tmin, to = tmax, by = stride *
dt)
ddiff <- rep(NA, length(wind))
for (ww in 1:length(wind)) {
wind.ww <- wind[ww]%%365
if (wind.ww == 0) {
wind.ww <- 365
}
if (wind.ww < min(testy$doy) | wind.ww > max(testy$doy)) {
next
}
ltest <- wind[ww] - wwidth * dt/2
if (ltest < tmin) {
next
}
rtest <- wind[ww] + wwidth * dt/2
if (rtest > tmax) {
break
}
if (rtest > ltest) {
tpd <- refy$tt > ltest & refy$tt <= rtest
}
if (rtest < ltest) {
tpd <- refy$tt > ltest | refy$tt <= rtest
}
lref <- min(refy$doy[abs(refy$tt - wind[ww]) <
dt/10] - refwidth * dt/2)%%365
if (lref == 0) {
lref == 365
}
rref <- max(refy$doy[abs(refy$tt - wind[ww]) <
dt/10] + refwidth * dt/2)%%365
if (rref == 0) {
rref == 365
}
if (rref > lref) {
rpd <- refy$doy > lref & refy$doy <= rref
}
if (rref < lref) {
rpd <- refy$doy > lref | refy$doy <= rref
}
if (sum(!is.na(refy$yy[tpd]))/wwidth < dmin |
sum(!is.na(refy$yy[rpd]))/refwidth < dmin) {
next
}
refdist <- ecdf(refy$yy[rpd])
wdist <- ecdf(refy$yy[tpd])
if (ddiff_method == "dist") {
ddiff[ww] <- max(abs(refdist(xx) - wdist(xx)))
}
else if (ddiff_method == "integral") {
ddiff[ww] <- dx * sum(abs(refdist(xx) - wdist(xx)))
}
}
ww
wind.ww <- wind[ww]%%365
wind.ww
wind.ww == 0
wind.ww < min(testy$doy) | wind.ww > max(testy$doy)
ltest <- wind[ww] - wwidth * dt/2
ltest
ltest < tmin
rtest <- wind[ww] + wwidth * dt/2
rtest
rtest > tmax
rtest > ltest
tpd <- refy$tt > ltest & refy$tt <= rtest
sum(tpd)
refy$tt - wind[ww]
abs(refy$tt - wind[ww])
dt/10
refy$tt
?mwdistdiffz
sort(unique(refy$doy))
sort(unique(refy$tt))
diff(sort(unique(refy$tt)))
diff(sort(unique(refy$tt)))
doy_diffs == diff(sort(unique(refy$tt)))
doy_diffs
doy_diffs == diff(sort(unique(refy$tt)))
doy_diffs = diff(sort(unique(refy$tt)))
doy_diffs
!all(doy_diffs == min(doy_diffs))
refy_complete_doys = data.frame(tt = seq(min(refy$tt), max(refy$tt)))
refy_complete_doys
refy_complete_doys = data.frame(tt = seq(min(refy$tt), max(refy$tt)))
refy = merge(refy_complete_doys, refy)
refy
?merge
# refy = data.frame(tt=unname(refyears$DOYtrunc), yy=unname(refyears$Manual_Chl))
refy = data.frame(tt=unname(refyears$DOY),
yy=unname(refyears$chl_epi))
doy_diffs = diff(sort(unique(refy$tt)))
if(!all(doy_diffs == min(doy_diffs))){
refy_complete_doys = data.frame(tt = seq(min(refy$tt), max(refy$tt)))
refy = merge(refy_complete_doys, refy, all=TRUE)
}
View(refy)
testint <-mwdistdiffz(testy_R15,refy,
wwidth=10, stride=1, refwidth = 120,
ddiff_method = "integral")
par(mfrow=c(2,1))
plot(testint[, c("wleft", "ddiff")], type="l", lwd=2)
plot(testint[, c("wleft", "zz")], type="l", lwd=2, col="red")
alarm<-disturbalarm(testint)
test<-alarmfilter(alarm, 5)
plot(testy_R15, col="blue", main="Chl", ylab="Chl")
points(refy, col="black")
abline(v=test$dist.date, col="red", lwd=2)
abline(v=test$recov.date, col="darkgreen", lwd=2)
plot(testint[, c("wleft", "zz")]
, type="l", lwd=2, col="red")
lakes = c("FI", "ME", "MO", "WI", "AL", "BM", "CB", "CR", "SP", "TB", "TR")
pdf("../../../Figures/secchi_timeseries_withPeaks.pdf", width=11, height=8.5)
for(i in 1:length(lakes)){
p = LTERsecchi %>%
filter(lakeid == lakes[i]) %>%
ggplot(aes(daynum, secnview)) +
geom_line() +
geom_point()+
geom_vline(data = secchi_peaks_formatted %>% filter(lakeid == lakes[i]),
aes(xintercept=daynum), size=1) +
facet_wrap(~year4, scales="free_y") +
theme_bw() +
ggtitle(paste(lakes[i], "Secchi", sep=" - ")) +
theme(legend.position = c(0.8, 0.08), legend.direction = "horizontal")
print(p)
}
dev.off()
setwd("~/Documents/PostDoc/Workshops/ntl_phenology/src/metric_checks/secchi")
library(NTLlakeloads)
library(tidyverse)
# data<-loadLTERsecchi()
inUrl1 <- "https://pasta.lternet.edu/package/data/eml/knb-lter-ntl/31/29/5a5a5606737d760b61c43bc59460ccc9"
infile1 <- tempfile()
download.file(inUrl1, infile1, method = "libcurl")
LTERsecchi <- read_csv(infile1, skip = 1, quote = "\"", guess_max = 1e+05,
col_names = c("lakeid", "year4", "daynum", "sampledate",
"sta", "secview", "secnview", "timeon", "timeoff",
"airtemp", "windir", "windspd", "waveht", "cloud",
"ice"))
table(LTERsecchi$lakeid)
# plot by DOY
ggplot(data=LTERsecchi,aes(x=daynum, y=secnview,col=as.factor(year4)))+
geom_point()+
geom_line()+
facet_wrap(~lakeid,scales="free")
# plot each lake-year separately
secchi_peaks_formatted = LTERsecchi %>%
group_by(lakeid, year4) %>%
slice_max(secnview) %>%
mutate(metric = "secchi") %>%
select(lakeid, metric, sampledate, year4, daynum, secnview)
# %>%
# rename(year = year4)
lakes = c("FI", "ME", "MO", "WI", "AL", "BM", "CB", "CR", "SP", "TB", "TR")
pdf("../../../Figures/secchi_timeseries_withPeaks.pdf", width=11, height=8.5)
for(i in 1:length(lakes)){
p = LTERsecchi %>%
filter(lakeid == lakes[i]) %>%
ggplot(aes(daynum, secnview)) +
geom_line() +
geom_point()+
geom_vline(data = secchi_peaks_formatted %>% filter(lakeid == lakes[i]),
aes(xintercept=daynum), size=1) +
facet_wrap(~year4, scales="free_y") +
theme_bw() +
ggtitle(paste(lakes[i], "Secchi", sep=" - ")) +
theme(legend.position = c(0.8, 0.08), legend.direction = "horizontal")
print(p)
}
dev.off()
# TODO: deal with when there's more than one peak with same max value in a year (see WI)
